<div align="center">
  <h1>Korcen</h1>
  <h2>Every journey begins with a single step.</h2>
</div>

![131_20220604170616](https://user-images.githubusercontent.com/85154556/171998341-9a7439c8-122f-4a9f-beb6-0e0b3aad05ed.png)

<div align="center">
  
  [![PyPI version](https://img.shields.io/pypi/v/korcen.svg?style=flat-square)](https://python.org/pypi/korcen)
  [![downloads](https://img.shields.io/pypi/dm/korcen.svg?style=flat-square)](https://pypi.org/project/korcen/)
</div>

<div align="center">
  <h2>
    <a href="https://github.com/Tanat05/korcen">EN</a>
    <a href="https://github.com/Tanat05/korcen/blob/main/readme/KR.md">KR</a>
  </h2>
</div>
Anyone can easily check

Although Korean slang is the main module, you can collect modules of other users to censor slang in other languages

[Example](https://github.com/KR-korcen/Example)

[ts version](https://github.com/KR-korcen/korcen.ts), [machine learning version](https://github.com/KR-korcen/korcen-ml)

[support discord](https://discord.gg/wyTU3ZQBPE)


## Project using Korcen
>[TNS ë´‡](https://discord.com/api/oauth2/authorize?client_id=848795383751639080&permissions=8&scope=bot%20applications.commands)

```
Discord Bot
3000+ servers
```

## Installation
>PyPI
```sh
$ pip install korcen
```

>Python
```py
from korcen import korcen

custom_include_text_1 = "ì´ ë¬¸ìž¥ì€ ë‚˜ë§Œì˜ ë¹„ì†ì–´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤."
print(f"Custom Include Test 1 ('{custom_include_text_1}'): {check(custom_include_text_1)}")
print(f"Highlight Custom Include 1: {highlight_profanity(custom_include_text_1, level='all')}")

custom_include_text_2 = "ì´ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€ êµ¬ë¬¸ìž…ë‹ˆë‹¤."
print(f"Custom Include Test 2 ('{custom_include_text_2}'): {check(custom_include_text_2)}")
print(f"Highlight Custom Include 2: {highlight_profanity(custom_include_text_2, level='all')}")

custom_exclude_text_sexual = "ì´ ì˜í™”ëŠ” ì •ë§ ë³´ì§€ë„ëª» í•  ìˆ˜ì¤€ì´ë‹¤."
print(f"Custom Exclude Test (Sexual) ('{custom_exclude_text_sexual}'): {check(custom_exclude_text_sexual)}")
print(f"Highlight Custom Exclude (Sexual): {highlight_profanity(custom_exclude_text_sexual, level='all')}")

custom_exclude_text_general = "ë¬´ìŠ¨ ì´ëŸ° ì§€ëž„ì´ì•¼!"
print(f"Custom Exclude Test (General) ('{custom_exclude_text_general}'): {check(custom_exclude_text_general)}")
print(f"Highlight Custom Exclude (General): {highlight_profanity(custom_exclude_text_general, level='all')}")

include_vs_exclude_text = "ë‚˜ë§Œì˜ ë¹„ì†ì–´ë¥¼ ì“°ë©´ì„œ ë¬´ìŠ¨ ì§€ëž„ì´ì•¼!"
print(f"Include vs Exclude Test ('{include_vs_exclude_text}'): {check(include_vs_exclude_text)}")
print(f"Highlight Include vs Exclude: {highlight_profanity(include_vs_exclude_text, level='all')}")

print("\n--- Demonstrating Changing Custom Filter Paths ---")
alt_include_file = 'alt_custom_include.txt'
alt_exclude_file = 'alt_custom_exclude.txt'

try:
    with open(alt_include_file, 'w', encoding='utf-8') as f:
        f.write("ìƒˆë¡œìš´ ë¹„ì†ì–´\n")
    with open(alt_exclude_file, 'w', encoding='utf-8') as f:
        f.write("ìƒˆë¡œìš´ì œì™¸ë‹¨ì–´\n")
    print(f"korcen: Created temporary test files: {alt_include_file}, {alt_exclude_file}")

    set_custom_filter_paths(include_path=alt_include_file, exclude_path=alt_exclude_file)

    new_include_text = "ì´ê²ƒì€ ìƒˆë¡œìš´ ë¹„ì†ì–´ìž…ë‹ˆë‹¤."
    print(f"New Include Test ('{new_include_text}'): {check(new_include_text)}")
    print(f"Highlight New Include: {highlight_profanity(new_include_text, level='all')}")

    old_include_text = "ë‚˜ë§Œì˜ ë¹„ì†ì–´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤."
    print(f"Old Include Test ('{old_include_text}') - Should NOT be flagged: {check(old_include_text)}")

    new_exclude_text = "í…ŒìŠ¤íŠ¸ ë¬¸ìž¥ ìƒˆë¡œìš´ì œì™¸ë‹¨ì–´ ì—¬ê¸°."
    print(f"New Exclude Test ('{new_exclude_text}') - Should NOT be flagged: {check(new_exclude_text)}")
    print(f"Highlight New Exclude: {highlight_profanity(new_exclude_text, level='all')}")

except Exception as e:
    print(f"korcen: Error during changing paths test: {e}")
finally:
    if os.path.exists(alt_include_file):
        os.remove(alt_include_file)
    if os.path.exists(alt_exclude_file):
        os.remove(alt_exclude_file)
    print("korcen: Temporary test files removed.")
    set_custom_filter_paths()


print("\n--- Original Tests ---")
print("--- Boolean Checks (all levels) ---")
print(f"'ì‹œë°œë†ˆì•„' (general): {general('ì‹œë°œë†ˆì•„')}")
print(f"'ë³´ì§€ë§ˆ' (sexual - false positive): {sexual('ë³´ì§€ë§ˆ')}")
print(f"'ë‚´ ë³´ã…ˆã…£ ë³´ì—¬ì¤„ê²Œ' (sexual): {sexual('ë‚´ ë³´ã…ˆã…£ ë³´ì—¬ì¤„ê²Œ')}")
print(f"'í‹€ë”±ë…„ ë‚˜ê°€' (belittle): {belittle('í‹€ë”±ë…„ ë‚˜ê°€')}")
print(f"'ê¹œë‘¥ì´ êº¼ì ¸' (race): {race('ê¹œë‘¥ì´ êº¼ì ¸')}")
print(f"'ã„´ã„±ã…' (parent): {parent('ã„´ã„±ã…')}")
if BETTER_PROFANITY_LOADED:
    print(f"'you are a bitch' (english): {english('you are a bitch')}")
else:
    print("'you are a bitch' (english): SKIPPED (better_profanity not loaded)")
print(f"'ç³žé‡ŽéƒŽã‚' (japanese): {japanese('ç³žé‡ŽéƒŽã‚')}")
print(f"'ä»–åª½çš„' (chinese): {chinese('ä»–åª½çš„')}")
print(f"'ðŸ–•ðŸ»' (special): {special('ðŸ–•ðŸ»')}")
print(f"'ë¬¸ì£„ì•™ out' (politics): {politics('ë¬¸ì£„ì•™ out')}")

print("\n--- Highlighting Profanity (all levels) ---")
print(f"'ì‹œë°œë†ˆì•„' (general): {highlight_profanity('ì‹œë°œë†ˆì•„', level='general')}")
print(f"'ì‹œë°œë†ˆì•„ ëŠê·¸ë³´ì§€ ì°¢ì–´ì¤„ê¹Œ?' (all): {highlight_profanity('ì‹œë°œë†ˆì•„ ëŠê·¸ë³´ì§€ ì°¢ì–´ì¤„ê¹Œ?', level='all')}")
print(f"'ë‚´ ë³´ã…ˆã…£ ë³´ì—¬ì¤„ê²Œ' (sexual): {highlight_profanity('ë‚´ ë³´ã…ˆã…£ ë³´ì—¬ì¤„ê²Œ', level='sexual')}")
print(f"'ì´ëŸ° í‹€ë”±ë…„ì€ ì²˜ìŒë´' (belittle): {highlight_profanity('ì´ëŸ° í‹€ë”±ë…„ì€ ì²˜ìŒë´', level='belittle')}")
print(f"'ì €ê¸° ê¹œë‘¥ì´ ì§€ë‚˜ê°„ë‹¤' (race): {highlight_profanity('ì €ê¸° ê¹œë‘¥ì´ ì§€ë‚˜ê°„ë‹¤', level='race')}")
print(f"'ì•„ ã„´ã„±ã… ë­í•˜ëƒ' (parent): {highlight_profanity('ì•„ ã„´ã„±ã… ë­í•˜ëƒ', level='parent')}")
if BETTER_PROFANITY_LOADED:
    print(f"'you are a stupid bitch' (english): {highlight_profanity('you are a stupid bitch', level='english')}")
print(f"'ì´ ç³žé‡ŽéƒŽì´!' (japanese): {highlight_profanity('ì´ ç³žé‡ŽéƒŽì´!', level='japanese')}")
print(f"'ä»–åª½çš„ë­ì•¼' (chinese): {highlight_profanity('ä»–åª½çš„ë­ì•¼', level='chinese')}")
print(f"'ì†ê°€ë½ ðŸ–•ðŸ» ê·¸ë§Œ' (special): {highlight_profanity('ì†ê°€ë½ ðŸ–•ðŸ» ê·¸ë§Œ', level='special')}")
print(f"'ìš°ë¦¬ ë¬¸ì£„ì•™ ëŒ€í†µë ¹ë‹˜' (politics): {highlight_profanity('ìš°ë¦¬ ë¬¸ì£„ì•™ ëŒ€í†µë ¹ë‹˜', level='politics')}")
print(f"'http://example.com/sex ì„¹ìŠ¤í•˜ìž' (sexual with URL): {highlight_profanity('http://example.com/sex ì„¹ìŠ¤í•˜ìž', level='sexual')}")

print("\n--- Comprehensive Check Function ---")
print(f"'ê·¸ëƒ¥ ì¼ë°˜ì ì¸ ë¬¸ìž¥ìž…ë‹ˆë‹¤.' (check): {check('ê·¸ëƒ¥ ì¼ë°˜ì ì¸ ë¬¸ìž¥ìž…ë‹ˆë‹¤.')}")
print(f"'ì‹œë°œ ì´ê²Œ ë§ì´ ë˜ëƒ' (check): {check('ì‹œë°œ ì´ê²Œ ë§ì´ ë˜ëƒ')}")
print(f"'ì•¼ìŠ¤ê°ì¸ë°?' (check): {check('ì•¼ìŠ¤ê°ì¸ë°?')}")
if BETTER_PROFANITY_LOADED:
    print(f"'This is absolute bullshit' (check): {check('This is absolute bullshit')}")
print(f"'êº¼ì ¸, ì´ ç³žé‡ŽéƒŽì•„' (check): {check('êº¼ì ¸, ì´ ç³žé‡ŽéƒŽì•„')}")
```

# Modules

KR : Self-produced

EN : [better_profanity](https://github.com/snguyenthanh/better_profanity)

JA : Self-produced

CH : Self-produced

# Maker


>Tanat
```
PyPI 0.0.1 ~

github:   Tanat05
discord:  Tanat#1533
email:    shrbwjd05@gmail.com
```


CopyrightÂ© All rights reserved.
